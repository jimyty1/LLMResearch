{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c7170c-5573-41b0-b0c6-9207b933b719",
   "metadata": {},
   "source": [
    "# Chapter 3 Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca39a15-f891-4c7d-9d4b-5bae0e6cf223",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in ./opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Using cached optree-0.18.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in ./opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.16.2-cp312-cp312-macosx_10_15_x86_64.whl (259.7 MB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl (393 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp312-cp312-macosx_10_13_x86_64.whl (369 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [tensorflow]6\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google-pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.1.0 opt-einsum-3.4.0 optree-0.18.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 termcolor-3.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2b0fd9-1014-4dc6-bdf2-01ecd8fb726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.3.0\n",
      "pandas version: 2.2.2\n",
      "tensorflow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\", # Deep learning library\n",
    "        \"pandas\", # Dataset loading\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights        \n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1f6c8c-c4b8-4eb9-80c1-8ba871ea3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663af506-5089-44c8-aa7b-c7fb85e810c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "\n",
    "query = inputs[1] \n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(attn_scores_2)\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c634fd9d-e3b0-40fa-b9f4-5ea5f286a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "0.002119779586791992\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# this way in the nested array we calculate the attention scores for each input token against all other tokens \n",
    "start = time.time()\n",
    "attn_scores = torch.empty(6,6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i,j] = torch.dot(x_i, x_j)\n",
    "elapsed = time.time() - start\n",
    "print(attn_scores)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "569f1c3b-38ce-4b0a-96d2-2a04a90720ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "0.0010459423065185547\n"
     ]
    }
   ],
   "source": [
    "#matrix mult saves time instead of doing the nested for loops\n",
    "start = time.time()\n",
    "attn_scores = inputs @ inputs.T\n",
    "elapsed = time.time() - start\n",
    "print(attn_scores)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d13d9aaf-433e-4ed8-bc1d-494623e3688b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1726c1e5-dab8-427a-955c-6fdb5bb18406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim = -1) \n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44c1b416-2178-4155-91e5-0823ab467697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4017, 0.5023, 0.5059],\n",
      "        [0.5595, 0.7824, 0.6953],\n",
      "        [0.5538, 0.7686, 0.6834],\n",
      "        [0.3369, 0.4647, 0.4119],\n",
      "        [0.3525, 0.4059, 0.3657],\n",
      "        [0.3856, 0.5761, 0.5077]])\n"
     ]
    }
   ],
   "source": [
    "# This is the tensor containing the context vectors for each input token which we get by \n",
    "# using the attn_weights and multiplying the matrix against the inputs\n",
    "context_vecs = attn_weights @ inputs\n",
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72e8e-9c90-4018-b7da-ee02abaa2b81",
   "metadata": {},
   "source": [
    "# 3.4 Creating the self attention mechanism used in the original gpt2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c568c4e7-15b6-4349-b807-97ac80a1acb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1530e4590>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 \n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0f1c9fe-7804-45bd-b16e-98b40c356f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0177, 0.5637],\n",
      "        [1.0427, 0.5773],\n",
      "        [1.0428, 0.5774],\n",
      "        [1.0153, 0.5620],\n",
      "        [1.0286, 0.5701],\n",
      "        [1.0162, 0.5622]])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad = False)\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad = False)\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad = False)\n",
    "    def forward(self, x):\n",
    "        queries =  x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "sa = SelfAttention(d_in, d_out)\n",
    "print(sa(inputs))\n",
    "print(inputs.shape)\n",
    "print(sa.W_query.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3deba9cf-3995-4f65-8a68-3aa97eff8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa2 = SelfAttention2(d_in, d_out)\n",
    "print(sa2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dbdea-11fb-4267-8556-1cfa47f21f9a",
   "metadata": {},
   "source": [
    "# 3.5 Causal Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9e8f33e-77d5-44df-83fe-d86fadc1548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#using torch.tril we can make a mask as to not use future tokens while making the context vectors\n",
    "print(torch.tril(torch.ones(6,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c070f2a-529c-4fcc-b490-704816bc61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95dcd9be-2d7c-45e6-8fea-05fb06852640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa2.W_query(inputs)\n",
    "keys = sa2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "masked_simple = attn_weights*mask\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79f74bc4-f5a4-46a6-ab58-077502992c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)\n",
    "#this way each row sums to one and therefore has been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "901121e8-0580-4833-802b-595fb28fb980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1951, 0.1610, 0.1610, 0.1610, 0.1610, 0.1610],\n",
      "        [0.1914, 0.1842, 0.1561, 0.1561, 0.1561, 0.1561],\n",
      "        [0.1861, 0.1792, 0.1793, 0.1518, 0.1518, 0.1518],\n",
      "        [0.1789, 0.1753, 0.1753, 0.1736, 0.1484, 0.1484],\n",
      "        [0.1736, 0.1708, 0.1708, 0.1695, 0.1707, 0.1446],\n",
      "        [0.1712, 0.1666, 0.1666, 0.1646, 0.1666, 0.1644]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple_norm = torch.softmax(masked_simple, dim = -1)\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d3cfc858-5ce3-4150-b8b1-e96dc160f41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)\n",
    "# we use -inf instead of zeroes in order to be able to use softmax. if soft max was utilized before the mask then the terms\n",
    "#have to be renormalized after the mask is applied and if it is applied with the zeroed out tril it spreads the values to\n",
    "# fill the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43410c6a-a9c7-4db4-983b-36dd72ddec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed55da4-2fa7-4361-83af-c0e714bdd734",
   "metadata": {},
   "source": [
    "# 3.5.2 Usage of Dropout in order to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ab59340-af1a-4669-afec-654682991ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) # dropout rate of 50%\n",
    "example = torch.ones(6, 6) # create a matrix of ones\n",
    "\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1302133d-0f4c-434b-8218-671cd3712501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e2158bff-86de-449e-9d76-76b8436bb7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)\n",
    "# we use the stack method to make a baatch consisting of 2 inputs which for simplicity are the same input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9629a0b7-c9f0-49d4-80ba-78ed7976097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.dropout =  nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens], -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores/keys.shape[-1]**.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vector = attn_weights @ values\n",
    "        return context_vector\n",
    "        \n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7eed2-6f66-48f2-b412-b331065d9923",
   "metadata": {},
   "source": [
    "# 3.6 Single Head Attention to Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "14f1d347-03aa-4d46-b800-7ebd54086e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "#Multi head Attention is achieved by stacking multiple single heads \n",
    "\"\"\"The main idea behind multi-head attention is to run the attention mechanism multiple \n",
    "times (in parallel) with different, learned linear projections. \n",
    "This allows the model to jointly attend to information from different representation subspaces at different positions.\"\"\"\n",
    "#^from the book\n",
    "\n",
    "class MultiHeadWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "                                  for _ in range(num_heads)])\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim =-1)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6884fa2d-e669-40ec-a865-45a505399e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f05ad7b7-bfae-4765-8f9e-6b0eeace03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n",
      "a \n",
      " tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
      "          [0.8993, 0.0390, 0.9268, 0.7388],\n",
      "          [0.7179, 0.7058, 0.9156, 0.4340]],\n",
      "\n",
      "         [[0.0772, 0.3565, 0.1479, 0.5331],\n",
      "          [0.4066, 0.2318, 0.4545, 0.9737],\n",
      "          [0.4606, 0.5159, 0.4220, 0.5786]]]]) \n",
      "\n",
      "a transposed 2 to 3\n",
      "  tensor([[[[0.2745, 0.8993, 0.7179],\n",
      "          [0.6584, 0.0390, 0.7058],\n",
      "          [0.2775, 0.9268, 0.9156],\n",
      "          [0.8573, 0.7388, 0.4340]],\n",
      "\n",
      "         [[0.0772, 0.4066, 0.4606],\n",
      "          [0.3565, 0.2318, 0.5159],\n",
      "          [0.1479, 0.4545, 0.4220],\n",
      "          [0.5331, 0.9737, 0.5786]]]]) \n",
      "\n",
      "a matrix mult by a transposed 2 to 3 \n",
      " tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "print(a.shape)\n",
    "print(\"a \\n\",a, \"\\n\")\n",
    "print(\"a transposed 2 to 3\\n \", a.transpose(2,3), \"\\n\")\n",
    "print(\"a matrix mult by a transposed 2 to 3 \\n\", a @ a.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8f17324b-faf6-40b9-9f64-b99abcda371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ab052-e8bc-44db-970a-b9d95f6ff9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
